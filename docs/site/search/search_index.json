{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"MARGARITA","text":"<p>MARGARITA is a lightweight templating tool for building prompt and markdown templates with metadata, context, and simple control flow.</p> <p>Key features</p> <ul> <li>Simple variable substitution with JSON contexts</li> <li>Template metadata for task information (e.g. <code>@task</code>, <code>@owner</code>)</li> <li>Conditionals and loops for dynamic sections</li> <li>Include files to compose templates across multiple fragments</li> <li>CLI for rendering and metadata inspection (<code>margarita render</code>, <code>margarita metadata</code>)</li> </ul> <p>Quick example</p> <p>Create <code>hello.marg</code> containing:</p> <pre><code>Hello, {{name}}!\n</code></pre> <p>Render with a JSON context:</p> <pre><code>margarita render hello.marg -c '{\"name\": \"World\"}'\n</code></pre> <p>Rendered result</p> <p>Given the template above and the context <code>{\"name\": \"World\"}</code>, the rendered output will be:</p> <pre><code>Hello, World!\n</code></pre> <p>See also: <code>Getting Started</code>, <code>Language Reference</code> pages (Contexts, Metadata, Conditionals, Loops, Include Files).</p>"},{"location":"basic/","title":"Basic Python Usage","text":"<p>First, import the necessary components:</p> <pre><code>from pathlib import Path\nfrom margarita.parser import Parser\nfrom margarita.renderer import Renderer\n</code></pre> <p>Render a template programmatically:</p> <pre><code># Define your template\ntemplate = \"\"\"\nYou are a helpful assistant.\n\nTask: {{task}}\n\n{% if context %}\nContext:\n{{context}}\n{% endif %}\n\nPlease provide a detailed response.\n\"\"\"\n\n# Parse the template\nparser = Parser()\nmetadata, nodes = parser.parse(template)\n\n# Create a renderer with context\nrenderer = Renderer(context={\n    \"task\": \"Summarize the key points\",\n    \"context\": \"User is researching AI agents\"\n})\n\n# Render the output\nprompt = renderer.render(nodes)\nprint(prompt)\n</code></pre>"},{"location":"conditionals/","title":"Conditionals","text":"<p>Use conditionals to render sections conditionally based on context values.</p> <p>Syntax</p> <pre><code>{% if subscribed %}\nThanks for subscribing, {{name}}!\n{% else %}\nPlease consider subscribing.\n{% endif %}\n</code></pre> <p>Rendered results</p> <ul> <li>When <code>subscribed</code> is true and <code>name</code> is <code>Dana</code>:</li> </ul> <pre><code>Thanks for subscribing, Dana!\n</code></pre> <ul> <li>When <code>subscribed</code> is false or missing:</li> </ul> <pre><code>Please consider subscribing.\n</code></pre> <p>Notes</p> <ul> <li>Conditions evaluate truthiness: missing, false, empty, or null values are treated as false.</li> <li>You can reference nested values with dotted paths, e.g. <code>user.active</code>.</li> <li>There is no support for complex expressions \u2014 stick to presence and simple boolean checks.</li> </ul> <p>Tip: Use <code>margarita metadata</code> or a dry render to ensure required context keys are present before running in production.</p>"},{"location":"contexts/","title":"Contexts","text":"<p>Contexts are plain JSON objects that supply variables to templates. Keys map to template variables and can include nested objects and arrays.</p> <p>Example context</p> <pre><code>{\n  \"name\": \"Batman\",\n  \"user\": { \"id\": 42, \"active\": true },\n  \"items\": [\"a\", \"b\", \"c\"]\n}\n</code></pre> <p>Rendered result</p> <p>Given the following template:</p> <pre><code>Hello, {{name}}! (id={{user.id}}, active={{user.active}})\n</code></pre> <p>Rendering with the example context produces:</p> <pre><code>Hello, Batman! (id=42, active=True)\n</code></pre> <p>See also: <code>Metadata</code> page for template header metadata and usage.</p> <p>Behavior and precedence</p> <ul> <li>CLI <code>-c</code> (inline JSON) and <code>-f</code> (context file) override auto-detected context files.</li> <li>When rendering a single template, MARGARITA looks for a sibling <code>.json</code> file with the same base name.</li> <li>Metadata is parsed from the template and can be shown with <code>margarita render --show-metadata</code> or <code>margarita metadata</code>.</li> </ul> <p>Tip: Keep contexts explicit and small; prefer using a context file in CI to ensure reproducible renders.</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>A minimal walkthrough to render your first MARGARITA template.</p> <ol> <li>Create a template file <code>greeting.marg</code>:</li> </ol> <pre><code>Hello, {{name}}!\n</code></pre> <ol> <li>Provide a context (JSON) either inline or in a file <code>greeting.json</code>:</li> </ol> <pre><code>{\"name\": \"Alice\"}\n</code></pre> <ol> <li>Render the template with the CLI:</li> </ol> <pre><code>margarita render greeting.marg -f greeting.json\n</code></pre> <p>Rendered result</p> <p>Using the template and context above the output will be:</p> <pre><code>Hello, Alice!\n</code></pre> <p>Alternate options</p> <ul> <li>Pass context as a JSON string: <code>-c '{\"name\": \"Bob\"}'</code></li> <li>Render a directory of <code>.marg</code> files: <code>margarita render templates/ -o output/</code></li> <li>Inspect template metadata before rendering: <code>margarita render template.marg --show-metadata</code></li> </ul> <p>Tip: When rendering a single file, MARGARITA will auto-detect a same-name <code>.json</code> file (e.g. <code>greeting.json</code>) if no context is supplied.</p>"},{"location":"include_files/","title":"Include Files","text":"<p>Reuse template fragments using <code>{% include \"file.marg\" %}</code>. Includes are resolved relative to the including template's directory.</p> <p>Example</p> <p><code>header.marg</code>:</p> <pre><code>This is the header content.\n</code></pre> <p><code>page.marg</code>:</p> <pre><code>{% include \"header.marg\" %}\n\n# Page Title\n\nContent goes here using the same context.\n</code></pre> <p>Rendered result</p> <p>When rendering <code>page.marg</code>, the output will include the header content followed by the page body:</p> <pre><code>This is the header content.\n\n# Page Title\n\nContent goes here using the same context.\n</code></pre> <p>Behavior</p> <ul> <li>Included files have access to the same rendering context as the parent template.</li> <li>Paths are resolved relative to the parent template's directory (the CLI and renderer set <code>base_path</code>).</li> <li>Avoid circular includes; they can cause infinite loops or errors.</li> </ul>"},{"location":"include_files/#using-includes-in-python-api","title":"Using Includes in Python API","text":"<p>When using MARGARITA programmatically, you must set the <code>base_path</code> when creating the renderer. All include paths are resolved relative to this base path, not relative to the file doing the including.</p> <pre><code>from pathlib import Path\nfrom margarita.parser import Parser\nfrom margarita.renderer import Renderer\n\n# Parse your template\nparser = Parser()\ntemplate = '{% include \"header.marg\" %}\\n\\nMain content here.'\n_, nodes = parser.parse(template)\n\n# Set base_path - all includes resolve from here\nrenderer = Renderer(\n    context={\"title\": \"My Page\"},\n    base_path=Path(\"./templates\")  # header.marg will be loaded from ./templates/header.marg\n)\n\noutput = renderer.render(nodes)\n</code></pre> <p>Important: Even in nested includes, all paths are from <code>base_path</code>. If <code>snippets/section.marg</code> includes another file, it must use the full path from <code>base_path</code>:</p> <pre><code>{# Inside templates/snippets/section.marg #}\n{% include \"snippets/subsection.marg\" %}  {# NOT just \"subsection.marg\" #}\n</code></pre> <p>See the Using Includes page for comprehensive examples and patterns.</p> <p>Tip: Use includes for headers, footers, and small shared components to keep templates DRY and maintainable.</p>"},{"location":"includes/","title":"Using Includes in Python API","text":"<p>MARGARITA's include functionality allows you to compose templates from reusable snippets, making it easy to build modular, maintainable prompt libraries. This page covers how to use includes programmatically through the Python API.</p>"},{"location":"includes/#basic-include-usage","title":"Basic Include Usage","text":""},{"location":"includes/#setting-up-the-renderer","title":"Setting Up the Renderer","text":"<p>The key to using includes is setting the <code>base_path</code> parameter when creating a <code>Renderer</code>. This tells MARGARITA where to resolve relative include paths:</p> <pre><code>from pathlib import Path\nfrom margarita.parser import Parser\nfrom margarita.renderer import Renderer\n\n# Define base path for includes\ntemplate_dir = Path(\"./templates\")\n\n# Parse your main template\nparser = Parser()\ntemplate_content = \"\"\"\n{% include \"header.marg\" %}\n\nMain content here.\n\n{% include \"footer.marg\" %}\n\"\"\"\n\nmetadata, nodes = parser.parse(template_content)\n\n# Create renderer with base_path\nrenderer = Renderer(\n    context={\"app_name\": \"MyApp\"},\n    base_path=template_dir\n)\n\n# Render - includes will be resolved relative to base_path\noutput = renderer.render(nodes)\n</code></pre>"},{"location":"includes/#creating-reusable-snippets","title":"Creating Reusable Snippets","text":""},{"location":"includes/#example-prompt-building-blocks","title":"Example: Prompt Building Blocks","text":"<p>Create a library of reusable prompt components:</p> <p>templates/snippets/system_role.marg: <pre><code>You are {{role}}, a helpful AI assistant.\n</code></pre></p> <p>templates/snippets/task_context.marg: <pre><code>## Task Context\n\nUser: {{user_name}}\nSession: {{session_id}}\nTimestamp: {{timestamp}}\n</code></pre></p> <p>templates/snippets/output_format.marg: <pre><code>## Output Requirements\n\n- Provide responses in {{format}} format\n- Keep responses {{length}}\n- Use {{tone}} tone\n</code></pre></p>"},{"location":"includes/#using-the-snippets","title":"Using the Snippets","text":"<pre><code>from pathlib import Path\nfrom margarita.parser import Parser\nfrom margarita.renderer import Renderer\n\n# Main template that composes snippets\nmain_template = \"\"\"\n{% include \"snippets/system_role.marg\" %}\n\n{% include \"snippets/task_context.marg\" %}\n\n## User Request\n\n{{user_request}}\n\n{% include \"snippets/output_format.marg\" %}\n\"\"\"\n\n# Parse and render\nparser = Parser()\n_, nodes = parser.parse(main_template)\n\nrenderer = Renderer(\n    context={\n        \"role\": \"technical expert\",\n        \"user_name\": \"Alice\",\n        \"session_id\": \"sess_123\",\n        \"timestamp\": \"2024-01-19T10:30:00Z\",\n        \"user_request\": \"Explain quantum computing\",\n        \"format\": \"markdown\",\n        \"length\": \"concise\",\n        \"tone\": \"professional\"\n    },\n    base_path=Path(\"./templates\")\n)\n\nprompt = renderer.render(nodes)\nprint(prompt)\n</code></pre>"},{"location":"includes/#dynamic-include-loading","title":"Dynamic Include Loading","text":""},{"location":"includes/#margaritacomposer","title":"MargaritaComposer","text":"<p>Include complex prompts dynamically using <code>Composer</code>:</p> <pre><code>from pathlib import Path\nfrom margarita.composer import Composer\n\n# Usage\nmanager = Composer(Path(\"./templates\"))\n\n# Compose a complex prompt from multiple snippets\nprompt = manager.compose_prompt(\n    snippets=[\n        \"snippets/system_role.marg\",\n        \"snippets/task_context.marg\",\n        \"snippets/chain_of_thought.marg\",\n        \"snippets/output_format.marg\"\n    ],\n    context={\n        \"role\": \"data scientist\",\n        \"user_name\": \"Bob\",\n        \"task\": \"Analyze customer churn\",\n        \"format\": \"JSON\",\n        \"tone\": \"analytical\"\n    }\n)\n</code></pre>"},{"location":"includes/#conditional-snippet-loading","title":"Conditional Snippet Loading","text":""},{"location":"includes/#using-conditionals-with-includes","title":"Using Conditionals with Includes","text":"<pre><code>from margarita.parser import Parser\nfrom margarita.renderer import Renderer\n# Template with conditional includes\ntemplate = \"\"\"\n{% include \"snippets/system_role.marg\" %}\n\n{% if use_examples %}\n{% include \"snippets/few_shot_examples.marg\" %}\n{% endif %}\n\n## Task\n\n{{task}}\n\n{% if detailed_output %}\n{% include \"snippets/detailed_format.marg\" %}\n{% else %}\n{% include \"snippets/brief_format.marg\" %}\n{% endif %}\n\"\"\"\n\nparser = Parser()\n_, nodes = parser.parse(template)\n\n# Render with detailed mode\nrenderer = Renderer(\n    context={\n        \"role\": \"assistant\",\n        \"use_examples\": True,\n        \"task\": \"Summarize the article\",\n        \"detailed_output\": True\n    },\n    base_path=Path(\"./templates\")\n)\n\nprompt = renderer.render(nodes)\n</code></pre>"},{"location":"includes/#nested-includes","title":"Nested Includes","text":"<p>Includes can reference other includes, creating a hierarchy of snippets. Important: All include paths are always resolved relative to the <code>base_path</code> set in the renderer, not relative to the file doing the including.</p>"},{"location":"includes/#understanding-base-path-resolution","title":"Understanding Base Path Resolution","text":"<p>Given this directory structure:</p> <pre><code>templates/\n  main.marg\n  snippets/\n    complete_prompt.marg\n    header_section.marg\n    system_role.marg\n    safety_guidelines.marg\n    body_section.marg\n    footer_section.marg\n</code></pre> <p>templates/snippets/complete_prompt.marg: <pre><code>{% include \"snippets/header_section.marg\" %}\n\n{% include \"snippets/body_section.marg\" %}\n\n{% include \"snippets/footer_section.marg\" %}\n</code></pre></p> <p>templates/snippets/header_section.marg: <pre><code>{% include \"snippets/system_role.marg\" %}\n\n{% include \"snippets/safety_guidelines.marg\" %}\n</code></pre></p> <p>Notice that even though <code>header_section.marg</code> is in the <code>snippets/</code> directory, it still uses <code>\"snippets/system_role.marg\"</code> in its include statement, not just <code>\"system_role.marg\"</code>. This is because all paths are resolved from <code>base_path</code>.</p>"},{"location":"includes/#example-nested-include-rendering","title":"Example: Nested Include Rendering","text":"<pre><code>from pathlib import Path\nfrom margarita.parser import Parser\nfrom margarita.renderer import Renderer\n\n# Parse the main template\nparser = Parser()\n_, nodes = parser.parse('{% include \"snippets/complete_prompt.marg\" %}')\n\n# Set base_path to templates/\nrenderer = Renderer(\n    context={\"role\": \"assistant\"},\n    base_path=Path(\"./templates\")\n)\n\n# All includes are resolved from ./templates/\n# - snippets/complete_prompt.marg -&gt; ./templates/snippets/complete_prompt.marg\n# - snippets/header_section.marg -&gt; ./templates/snippets/header_section.marg\n# - snippets/system_role.marg -&gt; ./templates/snippets/system_role.marg\noutput = renderer.render(nodes)\n</code></pre>"},{"location":"includes/#deep-nesting-example","title":"Deep Nesting Example","text":"<p>You can nest includes as deeply as needed:</p> <p>templates/layouts/full_prompt.marg: <pre><code>{% include \"sections/preamble.marg\" %}\n\n{% include \"sections/main_content.marg\" %}\n\n{% include \"sections/conclusion.marg\" %}\n</code></pre></p> <p>templates/sections/preamble.marg: <pre><code>{% include \"components/header.marg\" %}\n\n{% include \"components/instructions.marg\" %}\n</code></pre></p> <p>templates/components/header.marg: <pre><code>{% include \"atoms/logo.marg\" %}\n\n{% include \"atoms/title.marg\" %}\n</code></pre></p> <pre><code># All paths resolve from base_path, no matter how deep the nesting\nparser = Parser()\n_, nodes = parser.parse('{% include \"layouts/full_prompt.marg\" %}')\n\nrenderer = Renderer(\n    context={\"title\": \"My Prompt\"},\n    base_path=Path(\"./templates\")\n)\n\noutput = renderer.render(nodes)\n</code></pre>"},{"location":"includes/#why-base-path-matters","title":"Why Base Path Matters","text":"<p>This design makes your templates portable and predictable:</p> <pre><code># \u2705 CORRECT: All paths from base_path\n# templates/snippets/section.marg contains:\n{% include \"snippets/subsection.marg\" %}\n\n# \u274c WRONG: Don't use relative paths from the current file\n# templates/snippets/section.marg should NOT contain:\n{% include \"subsection.marg\" %}  # This won't work!\n</code></pre>"},{"location":"includes/#practical-tip-organizing-nested-structures","title":"Practical Tip: Organizing Nested Structures","text":"<p>Use consistent path prefixes to make nested includes clear:</p> <pre><code>templates/\n  prompts/\n    agent/\n      researcher.marg    -&gt; includes \"components/agent/...\"\n      analyzer.marg      -&gt; includes \"components/agent/...\"\n  components/\n    agent/\n      role.marg          -&gt; includes \"atoms/agent/...\"\n      tools.marg         -&gt; includes \"atoms/agent/...\"\n  atoms/\n    agent/\n      identity.marg\n      capabilities.marg\n</code></pre> <p>This structure makes it obvious that all includes use the full path from <code>templates/</code>.</p>"},{"location":"includes/#error-handling","title":"Error Handling","text":"<p>Always handle include errors gracefully:</p> <pre><code>from pathlib import Path\nfrom margarita.parser import Parser\nfrom margarita.renderer import Renderer\n\n\ndef safe_render(template_content: str, context: dict, base_path: Path) -&gt; str:\n    \"\"\"Safely render a template with error handling.\"\"\"\n    try:\n        parser = Parser()\n        _, nodes = parser.parse(template_content)\n\n        renderer = Renderer(context=context, base_path=base_path)\n        return renderer.render(nodes)\n\n    except FileNotFoundError as e:\n        # Handle missing include files\n        print(f\"Warning: Include file not found - {e}\")\n        return template_content  # Return unrendered template\n\n    except Exception as e:\n        # Handle other rendering errors\n        print(f\"Error rendering template: {e}\")\n        return \"\"\n\n\n# Usage\nresult = safe_render(\n    '{% include \"optional_snippet.marg\" %}\\nMain content.',\n    context={},\n    base_path=Path(\"./templates\")\n)\n</code></pre>"},{"location":"includes/#best-practices","title":"Best Practices","text":""},{"location":"includes/#1-organize-snippets-by-purpose","title":"1. Organize Snippets by Purpose","text":"<pre><code>templates/\n  snippets/\n    system/\n      role_definitions.marg\n      safety_guidelines.marg\n    formatting/\n      json_output.marg\n      markdown_output.marg\n    examples/\n      few_shot_classification.marg\n      few_shot_extraction.marg\n    sections/\n      header.marg\n      footer.marg\n</code></pre>"},{"location":"includes/#2-use-descriptive-naming","title":"2. Use Descriptive Naming","text":"<pre><code># Good: Clear, descriptive names\n{% include \"snippets/system/expert_role.marg\" %}\n{% include \"snippets/formatting/structured_json_output.marg\" %}\n\n# Avoid: Vague names\n{% include \"snippets/s1.marg\" %}\n{% include \"snippets/format.marg\" %}\n</code></pre>"},{"location":"includes/#3-keep-snippets-focused","title":"3. Keep Snippets Focused","text":"<p>Each snippet should have a single, clear purpose:</p> <pre><code># Good: Focused snippet\n# file: role_definition.marg\nYou are a {{role}} with expertise in {{domain}}.\n</code></pre> <pre><code># Avoid: Mixing multiple concerns\n# file: everything.marg\nYou are a {{role}}.\nTask: {{task}}\nOutput format: {{format}}\n</code></pre>"},{"location":"includes/#4-document-snippet-context-requirements","title":"4. Document Snippet Context Requirements","text":"<p>Add metadata to snippets documenting required context variables:</p> <pre><code>---\nname: role-definition\nversion: 1.0.0\nrequired_context:\n  - role\n  - domain\n  - expertise_level\n---\n\nYou are a {{role}} with {{expertise_level}} expertise in {{domain}}.\n</code></pre>"},{"location":"includes/#5-cache-parsed-templates","title":"5. Cache Parsed Templates","text":"<p>Parse templates once, render many times:</p> <pre><code>class OptimizedRenderer:\n    def __init__(self, template_dir: Path):\n        self.template_dir = template_dir\n        self.parser = Parser()\n        self.parsed_cache = {}\n\n    def get_nodes(self, template_content: str):\n        cache_key = hash(template_content)\n\n        if cache_key not in self.parsed_cache:\n            _, nodes = self.parser.parse(template_content)\n            self.parsed_cache[cache_key] = nodes\n\n        return self.parsed_cache[cache_key]\n\n    def render(self, template_content: str, context: dict) -&gt; str:\n        nodes = self.get_nodes(template_content)\n        renderer = Renderer(context=context, base_path=self.template_dir)\n        return renderer.render(nodes)\n</code></pre>"},{"location":"includes/#real-world-example-multi-agent-system","title":"Real-World Example: Multi-Agent System","text":"<pre><code>from pathlib import Path\nfrom margarita.parser import Parser\nfrom margarita.renderer import Renderer\n\n\nclass AgentPromptBuilder:\n    \"\"\"Build prompts for different agent types using snippets.\"\"\"\n\n    def __init__(self, snippets_dir: Path):\n        self.snippets_dir = snippets_dir\n        self.parser = Parser()\n\n    def build_agent_prompt(\n            self,\n            agent_type: str,\n            task: str,\n            context: dict\n    ) -&gt; str:\n        \"\"\"Build a prompt for a specific agent type.\"\"\"\n\n        # Map agent types to snippet combinations\n        snippet_map = {\n            \"researcher\": [\n                \"roles/researcher.marg\",\n                \"capabilities/web_search.marg\",\n                \"output/structured_findings.marg\"\n            ],\n            \"analyzer\": [\n                \"roles/analyzer.marg\",\n                \"capabilities/data_analysis.marg\",\n                \"output/insights_report.marg\"\n            ],\n            \"writer\": [\n                \"roles/writer.marg\",\n                \"capabilities/content_creation.marg\",\n                \"output/polished_text.marg\"\n            ]\n        }\n\n        snippets = snippet_map.get(agent_type, [])\n\n        # Build the main template\n        template = \"\\n\\n\".join([\n            f'{{% include \"{snippet}\" %}}'\n            for snippet in snippets\n        ])\n\n        template += f\"\\n\\n## Current Task\\n\\n{task}\"\n\n        # Render\n        _, nodes = self.parser.parse(template)\n        renderer = Renderer(\n            context=context,\n            base_path=self.snippets_dir\n        )\n\n        return renderer.render(nodes)\n\n\n# Usage\nbuilder = AgentPromptBuilder(Path(\"./agent_snippets\"))\n\n# Build a researcher agent prompt\nresearcher_prompt = builder.build_agent_prompt(\n    agent_type=\"researcher\",\n    task=\"Find the latest developments in quantum computing\",\n    context={\n        \"expertise\": \"quantum physics\",\n        \"sources\": [\"arxiv\", \"google scholar\"],\n        \"depth\": \"comprehensive\"\n    }\n)\n\n# Build an analyzer agent prompt\nanalyzer_prompt = builder.build_agent_prompt(\n    agent_type=\"analyzer\",\n    task=\"Analyze customer feedback trends\",\n    context={\n        \"data_source\": \"customer_reviews.json\",\n        \"analysis_type\": \"sentiment\",\n        \"output_format\": \"executive_summary\"\n    }\n)\n</code></pre>"},{"location":"loops/","title":"Loops","text":"<p>Render lists and repeat sections using <code>for</code> loops.</p> <p>Syntax</p> <pre><code># Items\n\n{% for item in items %}\n- {{item}}\n{% endfor %}\n</code></pre> <p>Example context</p> <pre><code>{ \"items\": [\"apple\", \"banana\", \"cherry\"] }\n</code></pre> <p>Rendered result</p> <p>Using the example context the rendered output will be:</p> <pre><code># Items\n\n- apple\n- banana\n- cherry\n</code></pre> <p>Notes</p> <ul> <li>The loop variable (<code>item</code> above) is whatever identifier you declare in the <code>for</code> statement.</li> <li><code>items</code> must be an array in the provided context.</li> <li>Nested loops are supported by composing loop blocks.</li> </ul> <p>Tip: Prepare and validate list data in the context rather than trying to transform large datasets inside the template.</p>"},{"location":"metadata/","title":"Metadata","text":"<p>Templates may declare metadata at the top using <code>@key: value</code> lines. This metadata can hold task information, ownership, or any other small key/value pairs that help describe the template's purpose.</p> <p>Example</p> <pre><code>@task: greeting\n@owner: docs-team\n@version: 2.0\n\nHello, {{name}}!\n</code></pre> <p>Behavior and precedence</p> <ul> <li>CLI <code>-c</code> (inline JSON) and <code>-f</code> (context file) override auto-detected context files.</li> <li>When rendering a single template, MARGARITA looks for a sibling <code>.json</code> file with the same base name.</li> <li>Metadata is parsed from the template and can be shown with <code>margarita render --show-metadata</code> or <code>margarita metadata</code>.</li> </ul> <p>Usage notes</p> <ul> <li>Use metadata for small, human-facing descriptors (task, owner, tags), not for large structured data \u2014 keep heavy data in context files.</li> <li>Metadata values are strings parsed from the template header lines; treat them as descriptive only.</li> </ul> <p>See also: <code>Contexts</code> page for context structure and examples.</p>"},{"location":"use-in-agents/","title":"Using MARGARITA in Agentic Loops","text":"<p>MARGARITA's dynamic rendering capabilities make it ideal for use in agentic AI workflows where prompts need to be generated, modified, and refined through multiple iterations.</p>"},{"location":"use-in-agents/#why-margarita-for-agents","title":"Why MARGARITA for Agents?","text":"<p>Agentic systems often need to:</p> <ul> <li>Generate prompts dynamically based on changing context</li> <li>Iterate through multiple LLM calls with evolving state</li> <li>Maintain structured, versioned prompt templates</li> <li>Compose complex prompts from reusable components</li> </ul>"},{"location":"use-in-agents/#agentic-loop-example","title":"Agentic Loop Example","text":"<p>Here's a practical example of using MARGARITA in a multi-step agent workflow:</p> <pre><code>from pathlib import Path\nfrom margarita.parser import Parser\nfrom margarita.renderer import Renderer\n\n\nclass ResearchAgent:\n    def __init__(self, template_dir: Path):\n        self.template_dir = template_dir\n        self.parser = Parser()\n        self.conversation_history = []\n\n    def render_prompt(self, template_name: str, context: dict) -&gt; str:\n        \"\"\"Render a template with the given context.\"\"\"\n        template_path = self.template_dir / template_name\n        template_content = template_path.read_text()\n\n        _, nodes = self.parser.parse(template_content)\n        renderer = Renderer(\n            context=context,\n            base_path=self.template_dir\n        )\n        return renderer.render(nodes)\n\n    def research_loop(self, topic: str, max_iterations: int = 3):\n        \"\"\"Execute a research loop with iterative refinement.\"\"\"\n        findings = []\n\n        for iteration in range(max_iterations):\n            # Render the research prompt\n            prompt = self.render_prompt(\"research.marg\", {\n                \"topic\": topic,\n                \"iteration\": iteration + 1,\n                \"previous_findings\": findings,\n                \"history\": self.conversation_history\n            })\n\n            # Call your LLM (pseudo-code)\n            response = self.call_llm(prompt)\n\n            # Store findings\n            findings.append({\n                \"iteration\": iteration + 1,\n                \"query\": topic,\n                \"result\": response\n            })\n\n            # Update conversation history\n            self.conversation_history.append({\n                \"role\": \"assistant\",\n                \"content\": response\n            })\n\n            # Check if we should continue\n            if self.should_stop(response):\n                break\n\n        # Generate final summary\n        summary_prompt = self.render_prompt(\"summary.marg\", {\n            \"topic\": topic,\n            \"findings\": findings,\n            \"total_iterations\": len(findings)\n        })\n\n        return self.call_llm(summary_prompt)\n\n    def call_llm(self, prompt: str) -&gt; str:\n        \"\"\"Call your LLM API (implement with your preferred provider).\"\"\"\n        # Example: OpenAI, Anthropic, local model, etc.\n        pass\n\n    def should_stop(self, response: str) -&gt; bool:\n        \"\"\"Determine if the research loop should stop.\"\"\"\n        # Implement your stopping logic\n        return \"COMPLETE\" in response\n</code></pre>"},{"location":"use-in-agents/#template-examples","title":"Template Examples","text":""},{"location":"use-in-agents/#researchmarg","title":"research.marg","text":"<pre><code>---\nname: research-prompt\nversion: 1.0.0\ndescription: Iterative research prompt for agent loops\n---\n\nYou are a research assistant conducting iteration {{iteration}} of your research.\n\nTopic: {{topic}}\n\n{% if previous_findings %}\n## Previous Findings\n\n{% for finding in previous_findings %}\n### Iteration {{finding.iteration}}\n{{finding.result}}\n\n{% endfor %}\n{% endif %}\n\n{% if history %}\n## Conversation History\n\n{% for message in history %}\n**{{message.role}}**: {{message.content}}\n\n{% endfor %}\n{% endif %}\n\n## Your Task\n\nContinue researching this topic. Build upon previous findings and provide new insights.\nWhen your research is complete, include the word COMPLETE in your response.\n</code></pre>"},{"location":"use-in-agents/#summarymarg","title":"summary.marg","text":"<pre><code>---\nname: summary-prompt\nversion: 1.0.0\ndescription: Generate final summary from research findings\n---\n\n# Research Summary\n\nTopic: {{topic}}\nTotal Iterations: {{total_iterations}}\n\n## All Findings\n\n{% for finding in findings %}\n### Research Phase {{finding.iteration}}\n\n**Query**: {{finding.query}}\n\n**Results**:\n{{finding.result}}\n\n---\n\n{% endfor %}\n\n## Your Task\n\nSynthesize all the above findings into a coherent, comprehensive summary.\nHighlight key insights and actionable takeaways.\n</code></pre>"},{"location":"use-in-agents/#dynamic-context-updates","title":"Dynamic Context Updates","text":"<p>MARGARITA's renderer allows you to update context dynamically within your agent loop:</p> <pre><code># Initial context\ncontext = {\n    \"user_query\": \"Explain quantum computing\",\n    \"difficulty\": \"intermediate\",\n    \"previous_attempts\": []\n}\n\n# Parse template once\nparser = Parser()\n_, nodes = parser.parse(template_content)\n\n# Agent loop with evolving context\nfor i in range(5):\n    # Create renderer with current context\n    renderer = Renderer(context=context, base_path=Path(\".\"))\n    prompt = renderer.render(nodes)\n\n    # Get LLM response\n    response = call_llm(prompt)\n\n    # Update context for next iteration\n    context[\"previous_attempts\"].append({\n        \"attempt\": i + 1,\n        \"response\": response\n    })\n\n    # Adjust difficulty based on response quality\n    if \"too simple\" in response.lower():\n        context[\"difficulty\"] = \"advanced\"\n    elif \"too complex\" in response.lower():\n        context[\"difficulty\"] = \"beginner\"\n</code></pre>"}]}